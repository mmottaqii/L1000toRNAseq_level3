{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac26cb3-f363-48ea-90f3-cd7ccf219489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import loompy as lp\n",
    "#import crick\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tdigest\n",
    "from tdigest import TDigest\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560d1bb",
   "metadata": {},
   "source": [
    "# CSV to LOOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cce1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First perform on head, then the clean CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67812c7",
   "metadata": {},
   "source": [
    "## 1. Confirming the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061569e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('5_sorted_head.csv')\n",
    "\n",
    "# Extract the gene expression values from columns 23 onwards\n",
    "gene_expression_df = df.iloc[:, 16:]\n",
    "gene_expression_data = gene_expression_df.values.T\n",
    "\n",
    "print(\"Shape of gene_expression_data:\", gene_expression_data.shape)\n",
    "#print(\"Length of gene_expression_df.columns[16:]:\", len(gene_expression_df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca9d7e",
   "metadata": {},
   "source": [
    "## 2. Dimension diagnostic test (Not Neccessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not neccessary\n",
    "\n",
    "df = pd.read_csv('5_sorted_head.csv')\n",
    "\n",
    "# Select only the columns you're interested in (from index 16 onwards)\n",
    "gene_expression_df = df.iloc[:, 16:]\n",
    "\n",
    "# 1. Check for non-numeric data\n",
    "non_numeric_cols = gene_expression_df.select_dtypes(exclude=['number']).columns\n",
    "print(\"Columns with non-numeric data:\", non_numeric_cols)\n",
    "\n",
    "# 2. Check for missing data\n",
    "missing_data_cols = gene_expression_df.columns[gene_expression_df.isnull().any()]\n",
    "print(\"Columns with missing data:\", missing_data_cols)\n",
    "\n",
    "# 3. Check for columns with all identical values\n",
    "single_value_cols = gene_expression_df.columns[gene_expression_df.nunique() == 1]\n",
    "print(\"Columns with single unique value:\", single_value_cols)\n",
    "\n",
    "# Add any other checks you find relevant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7a2654",
   "metadata": {},
   "source": [
    "## 3. Printing samples attribute cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clean_head.csv\")\n",
    "\n",
    "rows = df.shape[0]\n",
    "columns = df.shape[1] \n",
    "print(f\"rows = {rows}\")\n",
    "print(f\"columns = {columns}\")\n",
    "print()\n",
    "\n",
    "print(\"samples' attributes:\")\n",
    "print(df.columns[:17])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4c0b3",
   "metadata": {},
   "source": [
    "## 4. Main operation (run separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ccf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import loompy as lp\n",
    "\n",
    "\n",
    "df = pd.read_csv('5_sorted_head.csv')\n",
    "\n",
    "# Extract the cell attributes from columns 0 to 22 (including)\n",
    "cell_attributes_df = df.iloc[:, :16]\n",
    "\n",
    "# Extract the gene expression values from columns 23 onwards\n",
    "gene_expression_df = df.iloc[:, 16:]\n",
    "gene_expression_df = gene_expression_df.replace([np.nan, np.inf, -np.inf], -1)\n",
    "\n",
    "\n",
    "# Transpose the gene expression DataFrame to have genes as rows and cells as columns\n",
    "gene_expression_data = gene_expression_df.values.T\n",
    "\n",
    "gene_expression_data = gene_expression_data.astype(float)\n",
    "\n",
    "\n",
    "# Convert gene names to a numpy array\n",
    "row_attrs = {\"gene\": df.columns[16:].astype('str').tolist()}\n",
    "\n",
    "\n",
    "# Create the col_attrs dictionary containing all cell attributes\n",
    "col_attrs = {}\n",
    "for i in range(len(cell_attributes_df)):\n",
    "    cell_attributes = cell_attributes_df.iloc[i].to_dict()\n",
    "    for attr, value in cell_attributes.items():\n",
    "        col_attrs.setdefault(attr, []).append(value)\n",
    "\n",
    "col_attrs = {attr: np.array(value) for attr, value in col_attrs.items()}\n",
    "\n",
    "        \n",
    "# Create the .loom file for gene expression data\n",
    "lp.create('16_head.loom', gene_expression_data, row_attrs=row_attrs, col_attrs=col_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b4693",
   "metadata": {},
   "source": [
    "# Checking loom file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad058281",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lp.connect('16_head.loom') as ds:\n",
    "    # Get the shape of the matrix\n",
    "    matrix_shape = ds.shape\n",
    "\n",
    "    # Get the row names (gene names)\n",
    "    row_names = ds.ra.gene\n",
    "\n",
    "    # Get the column names (cell attributes)\n",
    "    col_names = ds.ca.keys()\n",
    "\n",
    "    # Print the matrix shape\n",
    "    print(\"Matrix Shape:\", matrix_shape)\n",
    "\n",
    "    # Print the row names (gene names)\n",
    "    print(\"Row Attributes (Gene Names):\")\n",
    "    print(row_names)\n",
    "    print()\n",
    "\n",
    "    # Print the column names (cell attributes)\n",
    "    print(\"Column Names (Cell Attributes):\")\n",
    "    print(col_names)\n",
    "    print()\n",
    "\n",
    "    # Print the first 100 rows and columns along with the data\n",
    "    print(\"First 20 rows and columns:\")\n",
    "    print(ds[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e04ce1",
   "metadata": {},
   "source": [
    "## 2. Attributes of first col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b24b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lp.connect('16_head.loom') as ds:\n",
    "    # Get the attributes and their values for the first column (cell)\n",
    "    cell_attributes = ds.ca.items()\n",
    "\n",
    "    # Print the attributes and their values for the first column (cell)\n",
    "    print(\"Attributes and Values for the First Column (Cell):\")\n",
    "    print()\n",
    "    for attr, values in cell_attributes:\n",
    "        print(f\"{attr}: {values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db355520",
   "metadata": {},
   "source": [
    "## 3. How many 0 & -1 in loom file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lp.connect(\"16_head.loom\") as ds:\n",
    "    # Count the occurrences of -1 in the entire dataset\n",
    "    num_negative_ones = (ds[:, :] == 0).sum()\n",
    "\n",
    "print(\"Number of 0 values in the whole dataset:\", num_negative_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d4db3",
   "metadata": {},
   "source": [
    "## 4. Checkin genes with 1 unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lp.connect(\"16_head.loom\") as ds:\n",
    "    # Get the gene expression data\n",
    "    gene_expression_data = ds[:, :]\n",
    "    \n",
    "    # Calculate the number of unique values in each row (gene)\n",
    "    unique_counts_row = np.apply_along_axis(lambda x: len(np.unique(x)), axis=1, arr=gene_expression_data)\n",
    "    unique_counts_col = np.apply_along_axis(lambda x: len(np.unique(x)), axis=0, arr=gene_expression_data)\n",
    "    \n",
    "    # Find the indices of rows with only one unique value\n",
    "    #rows_with_one_unique_value = np.where(unique_counts == 1)[0]\n",
    "    rows_with_one_unique_value = np.where(unique_counts_row == 1)[0]\n",
    "    columns_with_one_unique_value = np.where(unique_counts_col == 1)[0]\n",
    "    \n",
    "    \n",
    "    # Print the row indices with only one unique value\n",
    "    print(\"Rows (gene expressions) with only one unique value:\")\n",
    "    print(rows_with_one_unique_value)\n",
    "    print(len(rows_with_one_unique_value))\n",
    "    print()\n",
    "    \n",
    "    print(\"Colomns (samples) with only one unique value:\")\n",
    "    print(columns_with_one_unique_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547bf8f1",
   "metadata": {},
   "source": [
    "## 5. Histogram of genes with 1 uniue value (needs indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8baea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only if there is any genes with 1 unique value\n",
    "\n",
    "with lp.connect(\"3_head.loom\") as ds:\n",
    "    # Get the gene expression data for the selected rows\n",
    "    gene_expression_data = ds[12328:13305, :]\n",
    "    \n",
    "    # Flatten the data to create a 1D array of all values in the selected rows\n",
    "    flattened_data = gene_expression_data.flatten()\n",
    "    \n",
    "    # Filter out -1 values from the array\n",
    "    filtered_data = flattened_data[flattened_data != -1]\n",
    "    \n",
    "    # Calculate the distribution of unique values and their counts\n",
    "    unique_values, counts = np.unique(filtered_data, return_counts=True)\n",
    "    \n",
    "    # Plot the histogram using Seaborn\n",
    "    sns.histplot(filtered_data)\n",
    "    plt.title(\"Genes with one unique expression value in mcf7 dataset\")\n",
    "    plt.xlabel(\"Unique Values\")\n",
    "    plt.ylabel(\"Counts\")\n",
    "    plt.xlim(-10,5)\n",
    "    plt.show()\n",
    "    plt.savefig(\"cells_values_mcf7.png\", dpi=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b7e1f",
   "metadata": {},
   "source": [
    "## 6. Masking genes (add attr) with one unique value (zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import loompy as lp\n",
    "import numpy as np\n",
    "\n",
    "input_loom_file = \"16_head.loom\"  # Replace with your loom file path\n",
    "chunk_size = 1000  # Number of rows to read at a time\n",
    "\n",
    "# Initialize an empty array for the new attribute\n",
    "new_attribute = np.zeros(0, dtype=int)\n",
    "\n",
    "# Connect to the loom file\n",
    "with lp.connect(input_loom_file) as ds:\n",
    "    n_rows = ds.shape[0]\n",
    "    \n",
    "    for (ix, selection, view) in ds.scan(axis=0, batch_size=chunk_size):\n",
    "        chunk_data = view[:, :]\n",
    "        \n",
    "        # Temporary array to store attribute values for this chunk\n",
    "        temp_attribute = np.zeros(chunk_data.shape[0], dtype=int)\n",
    "        \n",
    "        # Loop through each row of the chunk and count unique values\n",
    "        for i in range(chunk_data.shape[0]):\n",
    "            row_data = chunk_data[i, :]\n",
    "            unique_values = np.unique(row_data)\n",
    "            \n",
    "            # Check if the row has only one unique value\n",
    "            if len(unique_values) == 1:\n",
    "                temp_attribute[i] = 0  # Set to 0 if only one unique value\n",
    "            else:\n",
    "                temp_attribute[i] = 1  # Set to 1 otherwise\n",
    "                \n",
    "        # Append the temporary array to the new attribute array\n",
    "        new_attribute = np.concatenate((new_attribute, temp_attribute))\n",
    "        \n",
    "    # Add the new attribute to the loom file\n",
    "    ds.ra['UniqueValueIndicator'] = new_attribute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5043f7",
   "metadata": {},
   "source": [
    "## 7. Checking the new attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71006276",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lp.connect(\"16_head.loom\") as ds:\n",
    "    unique_value_indicator = ds.ra[\"UniqueValueIndicator\"]\n",
    "    count_zeros = np.sum(unique_value_indicator == 0)\n",
    "\n",
    "print(f\"The number of zeros in the 'UniqueValueIndicator' attribute is: {count_zeros}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not necessary\n",
    "\n",
    "with lp.connect(\"16_head.loom\") as ds:\n",
    "    # Get the gene expression data\n",
    "    gene_expression_data = ds[:, :]\n",
    "    \n",
    "    # Get the values of the column with index 32\n",
    "    column_values = gene_expression_data[12330:12399, :]\n",
    "    \n",
    "    # Print the values of the column\n",
    "    print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71652398",
   "metadata": {},
   "source": [
    "## 8. printing specific columns values (with indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b52a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lp.connect(\"16_head.loom\") as ds:\n",
    "    # Get the gene expression data\n",
    "    gene_expression_data = ds[:, :]\n",
    "    \n",
    "    # Get the values of the column with index 32\n",
    "    column_values = gene_expression_data[12330:12350, :]\n",
    "    \n",
    "    # Print the values of the column\n",
    "    print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447db7f",
   "metadata": {},
   "source": [
    "# Adding n_counts to col attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6c6e1",
   "metadata": {},
   "source": [
    "## 1. Adding n_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds them instantly to the existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lp.connect(\"16_head.loom\") as ds:\n",
    "    # Create a mask for values equal to -1\n",
    "    mask = (ds[:, :] != -1)\n",
    "    \n",
    "    # Calculate the sum of expression values for each cell (column) while ignoring -1 values\n",
    "    cell_sums = (ds[:, :] * mask).sum(axis=0)\n",
    "    \n",
    "    # Add the sum as a column attribute 'n_counts' to the Loom file\n",
    "    ds.ca['n_counts'] = cell_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1312780e",
   "metadata": {},
   "source": [
    "## 2. Double checking n_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66908037",
   "metadata": {},
   "source": [
    "### 1. First 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7200e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lp.connect(\"16_head.loom\") as ds:\n",
    "    # Access the 'n_counts' attribute for the first 10 columns (cells)\n",
    "    n_counts_first_10 = ds.ca.n_counts[:10]\n",
    "\n",
    "print(n_counts_first_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360430f",
   "metadata": {},
   "source": [
    "### 2. First row n_counts in loom using np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lp.connect(\"3_head.loom\") as ds:\n",
    "    # Get the gene expression data as a numpy array\n",
    "    gene_expression_data = ds[:, :]\n",
    "\n",
    "    # Calculate the sum of values in the first column\n",
    "    sum_first_column = gene_expression_data[:, 0].sum()\n",
    "\n",
    "print(\"Sum of values in the first column:\", sum_first_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44402dba",
   "metadata": {},
   "source": [
    "### 3. First rows in csv n_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb288c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('5_sorted_head.csv')\n",
    "\n",
    "# Calculate the sum of values in the first row and ignore NaNs\n",
    "sum_first_row1 = pd.to_numeric(df.iloc[0, 16:], errors='coerce').sum()\n",
    "sum_first_row2 = pd.to_numeric(df.iloc[1, 16:], errors='coerce').sum()\n",
    "sum_first_row3 = pd.to_numeric(df.iloc[2, 16:], errors='coerce').sum()\n",
    "sum_first_row4 = pd.to_numeric(df.iloc[3, 16:], errors='coerce').sum()\n",
    "print(\"Sum of values in the first rows:\", sum_first_row1, sum_first_row2, sum_first_row3, sum_first_row4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b5b488",
   "metadata": {},
   "source": [
    "# Special characters in genes' names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76480be9",
   "metadata": {},
   "source": [
    "## 1. Checking of existance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# List of common special characters to check for\n",
    "special_characters = \"!@#$%^&*()-=[]{}|;:'\\\",.<>?/\"\n",
    "\n",
    "# Initialize list to store indices and column names with special characters\n",
    "indices_list = []\n",
    "column_names_list = []\n",
    "\n",
    "# Read only the header of the CSV file\n",
    "with open('5_sorted_head.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "\n",
    "    for idx, column_name in enumerate(header):\n",
    "        if any(char in special_characters for char in column_name):\n",
    "            indices_list.append(str(idx))\n",
    "            column_names_list.append(column_name)\n",
    "\n",
    "# Write the indices and column names to the output file\n",
    "with open('7.5_char_in_gene_names.txt', 'w') as f:\n",
    "    # Write indices\n",
    "    f.write(','.join(indices_list))\n",
    "    f.write('\\n')\n",
    "    \n",
    "    # Write column names\n",
    "    for name in column_names_list:\n",
    "        f.write(name)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea142de0",
   "metadata": {},
   "source": [
    "## 2. Chuncking gene names in 450 for each txt (for biomart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca29ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be written"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4bff06",
   "metadata": {},
   "source": [
    "## 3. Biomart check (Manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0bfab1",
   "metadata": {},
   "source": [
    "## 4. Comparison of genes in dataset with biomart genes (Ensemble IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65420f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using biomart - genes in chuncks of 500\n",
    "# ran on my own PC\n",
    "# First extract the genes names with special characters, chucks them and then check with biomart\n",
    "# code needs edit to export names in exclude.txt\n",
    "\n",
    "# Initialize an empty list to store the gene names\n",
    "all_gene_names = []\n",
    "\n",
    "# Loop through the seven text files\n",
    "for i in range(0, 7):\n",
    "    df = pd.read_csv(f\"{i}.txt\", delimiter=',', header=0)  # Using the first row as header\n",
    "    all_gene_names.extend(df['Gene name'].tolist())  # Extract the 'Gene name' column\n",
    "\n",
    "# Convert the combined gene names to a set for easier comparison\n",
    "all_gene_names_set = set(all_gene_names)\n",
    "\n",
    "# Read the other text file and convert its content into a set\n",
    "with open(\"7.5_char_total.txt\", \"r\") as file:\n",
    "    text_file_set = set(file.read().splitlines())\n",
    "\n",
    "# Find the strings not shared between the two sets\n",
    "#not_shared_in_text_file = all_gene_names_set - text_file_set\n",
    "not_shared_in_other_file = text_file_set - all_gene_names_set\n",
    "print(len(not_shared_in_other_file))\n",
    "#print(\"Strings not shared in the text file:\", not_shared_in_text_file)\n",
    "print(\"Strings not shared in the other file:\", not_shared_in_other_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd7494e",
   "metadata": {},
   "source": [
    "## 5. Masking gene names with special char (adding attr) from loom file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56572659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be applied on the complete dataset\n",
    "import loompy\n",
    "import numpy as np\n",
    "\n",
    "# Read the txt file to get the list of genes to exclude\n",
    "with open('exclude_genes.txt', 'r') as file:\n",
    "    exclude_genes = file.read().replace(\"'\", \"\").split(\", \")\n",
    "    exclude_genes = set(exclude_genes)  # Convert list to set for efficient lookup\n",
    "\n",
    "# Connect to the loom file\n",
    "with loompy.connect('your_file.loom') as ds:\n",
    "    # Get the gene names from the loom file\n",
    "    gene_names = ds.ra.gene  # Assuming the row attribute for gene names is \"gene\"\n",
    "\n",
    "    # Initialize a numpy array to store new row attributes\n",
    "    new_row_attribute = np.ones(ds.shape[0], dtype=int)  # Initialize with ones\n",
    "\n",
    "    # Loop through gene names and update the row attribute\n",
    "    for i, gene in enumerate(gene_names):\n",
    "        if gene in exclude_genes:\n",
    "            new_row_attribute[i] = 0  # Set to 0 if the gene is in the exclude list\n",
    "\n",
    "    # Add the new row attribute to the loom file\n",
    "    ds.ra['ExcludeFlag'] = new_row_attribute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e92dc7",
   "metadata": {},
   "source": [
    "# TDigest test practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_digest = TDigest()\n",
    "another_digest.batch_update(i for i in range(100))\n",
    "another_digest.update(0.55)\n",
    "print(another_digest.percentile(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_digests = TDigest()\n",
    "print(median_digests)\n",
    "median_digests.batch_update(i for i in range(5))\n",
    "print(median_digests)\n",
    "median_digests.update(1)\n",
    "print(median_digests)\n",
    "print(median_digests.percentile(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b40d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_digests = [TDigest() for i in range(3)]\n",
    "print(row_digests)\n",
    "row_digests[0].update(50,20) # 20 of 50s it means\n",
    "print(row_digests)\n",
    "print(row_digests[0].percentile(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dbc725",
   "metadata": {},
   "source": [
    "# NON-ZERO MEDIAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114cdde",
   "metadata": {},
   "source": [
    "## 1. Real median value of the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2681c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lp.connect(\"16_head.loom\") as ds:\n",
    "    # Get the gene expression data\n",
    "    gene_expression_data = ds[:, :]\n",
    "    n_counts_values = ds.ca.n_counts\n",
    "    \n",
    "    # Get the values of the first row\n",
    "    first_row_values0 = gene_expression_data[0, :]\n",
    "    first_row_values1 = gene_expression_data[1, :]\n",
    "    first_row_values2 = gene_expression_data[2, :]\n",
    "    \n",
    "    normalized_values0 = first_row_values0 / n_counts_values\n",
    "    normalized_values1 = first_row_values1 / n_counts_values\n",
    "    normalized_values2 = first_row_values2 / n_counts_values\n",
    "    \n",
    "    # Calculate the median\n",
    "    median_value0 = np.median(normalized_values0) * 10000\n",
    "    median_value1 = np.median(normalized_values1) * 10000\n",
    "    median_value2 = np.median(normalized_values2) * 10000\n",
    "    \n",
    "    # Print the median\n",
    "    print(\"Median of the rows:\", median_value0, median_value1, median_value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78de8b",
   "metadata": {},
   "source": [
    "## 2. Checking median for few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c936ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"16_head.loom\"\n",
    "output_file = input_file.replace(\".loom\", \".gene_median_digest_dict.pickle\")\n",
    "\n",
    "with lp.connect(f\"{input_file}\") as data:\n",
    "    # define coordinates of protein-coding or miRNA genes\n",
    "    coding_genes = data.ra.gene\n",
    "    # Rows(genes)\n",
    "    total_rows = data.shape[0]\n",
    "    print(total_rows)\n",
    "    #Cols(samples)\n",
    "    print(data.shape[1])\n",
    "\n",
    "    # Initiate tdigest\n",
    "    median_digests = [TDigest() for _ in range(3)]  # only the first 10 coding genes\n",
    "    # print the last one for checking later\n",
    "\n",
    "    # initiate progress meters\n",
    "    last_view_row = 0\n",
    "\n",
    "    \n",
    "    for (ix, selection, view) in data.scan(items=np.array(range(3)), axis=0):  # only the first 10 rows\n",
    "\n",
    "        # subview = view\n",
    "\n",
    "        # normalize by total counts per cell and multiply by 10,000 to allocate bits to precision\n",
    "        subview_norm_array = view[:,:]/view.ca.n_counts*10000\n",
    "        #print(subview_norm_array)\n",
    "        \n",
    "        if np.issubdtype(subview_norm_array.dtype, np.integer):\n",
    "            subview_norm_array = subview_norm_array.astype(np.float32)\n",
    "            \n",
    "        # mask zeroes from distribution tdigest by filling with nan\n",
    "        nonzero_data0 = np.ma.masked_equal(subview_norm_array, 0.0).filled(np.nan)\n",
    "        nonzero_data = np.ma.masked_equal(nonzero_data0, -1).filled(np.nan)\n",
    "\n",
    "        # update tdigestto review your data preprocessing steps\n",
    "        for i in range(nonzero_data.shape[0]):\n",
    "            median_digests[i+last_view_row].batch_update(nonzero_data[i,:])\n",
    "\n",
    "        # update progress meters\n",
    "        last_view_row = last_view_row + view.shape[0]\n",
    "\n",
    "print(median_digests)\n",
    "print(median_digests[0].percentile(50))\n",
    "print(median_digests[1].percentile(50))\n",
    "print(median_digests[2].percentile(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854683e6",
   "metadata": {},
   "source": [
    "## 3. Non-zero median value computation (prints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f778fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"16_head.loom\"\n",
    "output_file = input_file.replace(\".loom\", \".gene_median_digest_dict.pickle\")\n",
    "\n",
    "with lp.connect(f\"{input_file}\") as data:\n",
    "    # define coordinates of protein-coding or miRNA genes\n",
    "    coding_genes = data.ra.gene\n",
    "    # Rows(genes)\n",
    "    total_rows = data.shape[0]\n",
    "    print(total_rows)\n",
    "    #Cols(samples)\n",
    "    print(data.shape[1])\n",
    "\n",
    "    # Initiate tdigest\n",
    "    median_digests = [TDigest() for _ in range(len(coding_genes))]\n",
    "    # print the last one for checking later\n",
    "\n",
    "    # initiate progress meters\n",
    "    last_view_row = 0\n",
    "\n",
    "    \n",
    "    for (ix, selection, view) in data.scan(items=np.array(range(total_rows)), axis=0):\n",
    "        # subview = view\n",
    "\n",
    "        # normalize by total counts per cell and multiply by 10,000 to allocate bits to precision\n",
    "        subview_norm_array = view[:,:]/view.ca.n_counts*10000\n",
    "        #print(subview_norm_array)\n",
    "        \n",
    "        if np.issubdtype(subview_norm_array.dtype, np.integer):\n",
    "            subview_norm_array = subview_norm_array.astype(np.float32)\n",
    "            \n",
    "        # mask zeroes from distribution tdigest by filling with nan\n",
    "        nonzero_data0 = np.ma.masked_equal(subview_norm_array, 0.0).filled(np.nan)\n",
    "        nonzero_data = np.ma.masked_equal(nonzero_data0, -1).filled(np.nan)\n",
    "\n",
    "        # update tdigestto review your data preprocessing steps\n",
    "        for i in range(nonzero_data.shape[0]):\n",
    "            median_digests[i+last_view_row].batch_update(nonzero_data[i,:])\n",
    "\n",
    "        # update progress meters\n",
    "        last_view_row = last_view_row + view.shape[0]\n",
    "\n",
    "print(median_digests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDS TO BE EXPORTED AS A PICKLE FILE CONTAINING DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc025e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25be1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0858c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae1c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd3fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
